def process_frame(self, frame, frame_number=0):
        """프레임별 처리"""
        results = {
            'frame_number': frame_number,
            'persons': [],
            'total_emotions': defaultdict(int)
        }

        # YOLO로 사람 탐지
        yolo_results = self.yolo(frame, classes=[0], verbose=False)  # class 0 = person

        if yolo_results[0].boxes is not None:
            for i, box in enumerate(yolo_results[0].boxes):
                confidence = float(box.conf[0])
                if confidence < 0.5:  # 신뢰도가 낮으면 스킵
                    continue

                # 바운딩 박스 좌표
                x1, y1, x2, y2 = map(int, box.xyxy[0])

                # 사람 영역 자르기
                person_crop = frame[y1:y2, x1:x2]

                if person_crop.size == 0:
                    continue

                # 얼굴 검출
                faces = self.detect_faces_in_person(person_crop)

                person_data = {
                    'person_id': i,
                    'bbox': [x1, y1, x2, y2],
                    'yolo_confidence': confidence,
                    'faces': [],
                    'dominant_emotion': 'neutral',
                    'emotion_confidence': 0.0
                }

                # 각 얼굴에 대해 감정 분석
                if len(faces) > 0:
                    face_emotions = []

                    for (fx, fy, fw, fh) in faces:
                        # 절대 좌표로 변환
                        abs_fx, abs_fy = x1 + fx, y1 + fy
                        abs_fx2, abs_fy2 = abs_fx + fw, abs_fy + fh

                        # 얼굴 영역 자르기
                        face_crop = frame[abs_fy:abs_fy2, abs_fx:abs_fx2]

                        if face_crop.size == 0:
                            continue

                        # 감정 분석
                        emotion, emotion_conf, emotion_probs = self.emotion_analyzer.predict_emotion(face_crop)

                        face_data = {
                            'bbox': [abs_fx, abs_fy, abs_fx2, abs_fy2],
                            'emotion': emotion,
                            'confidence': emotion_conf,
                            'probabilities': emotion_probs
                        }

                        person_data['faces'].append(face_data)
                        face_emotions.append((emotion, emotion_conf))

                    # 가장 신뢰도 높은 감정을 사람의 대표 감정으로
                    if face_emotions:
                        best_emotion = max(face_emotions, key=lambda x: x[1])
                        person_data['dominant_emotion'] = best_emotion[0]
                        person_data['emotion_confidence'] = best_emotion[1]

                        # 통계 업데이트
                        self.person_emotions[i].append(best_emotion[0])
                        results['total_emotions'][best_emotion[0]] += 1

                results['persons'].append(person_data)

        self.frame_stats.append(results)
        return results

    def draw_annotations(self, frame, frame_results):
        """결과를 프레임에 그리기"""
        annotated_frame = frame.copy()

        for person in frame_results['persons']:
            x1, y1, x2, y2 = person['bbox']
            emotion = person['dominant_emotion']
            emotion_conf = person['emotion_confidence']

            # 감정에 따른 색상
            color = self.emotion_analyzer.emotion_colors.get(emotion, (255, 255, 255))

            # 사람 바운딩 박스
            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, 2)

            # 감정 라벨
            if emotion_conf > 0:
                label = f"{emotion}: {emotion_conf:.2f}"
                label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]

                # 라벨 배경
                cv2.rectangle(annotated_frame, (x1, y1 - label_size[1] - 10),
                              (x1 + label_size[0], y1), color, -1)

                # 라벨 텍스트
                cv2.putText(annotated_frame, label, (x1, y1 - 5),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)

            # 얼굴 바운딩 박스
            for face in person['faces']:
                fx1, fy1, fx2, fy2 = face['bbox']
                cv2.rectangle(annotated_frame, (fx1, fy1), (fx2, fy2), color, 1)

        # 전체 통계 표시
        y_offset = 30
        for emotion, count in frame_results['total_emotions'].items():
            if count > 0:
                text = f"{emotion}: {count}"
                cv2.putText(annotated_frame, text, (10, y_offset),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                y_offset += 25

        return annotated_frame

    def process_video(self, input_path, output_path=None, save_stats=True):
        """비디오 전체 처리"""
        cap = cv2.VideoCapture(input_path)

        if not cap.isOpened():
            print(f"❌ 비디오 파일을 열 수 없습니다: {input_path}")
            return None

        # 비디오 정보
        fps = cap.get(cv2.CAP_PROP_FPS)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

        print(f"📹 비디오 정보: {width}x{height}, {fps:.1f}FPS, {total_frames}프레임")

        # 출력 비디오 설정
        out = None
        if output_path:
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

        frame_number = 0
        start_time = time.time()

        print("🎬 감정분석 처리 시작...")

        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    break

                # 프레임 처리
                frame_results = self.process_frame(frame, frame_number)

                # 결과 그리기
                annotated_frame = self.draw_annotations(frame, frame_results)

                # 진행률 표시
                if frame_number % 30 == 0:
                    progress = (frame_number / total_frames) * 100
                    elapsed = time.time() - start_time
                    fps_processing = frame_number / elapsed if elapsed > 0 else 0
                    print(f"진행률: {progress:.1f}% ({frame_number}/{total_frames}) - {fps_processing:.1f} FPS")

                # 출력 비디오에 저장
                if out:
                    out.write(annotated_frame)

                frame_number += 1

            processing_time = time.time() - start_time
            print(f"✅ 처리 완료! 총 시간: {processing_time:.1f}초")

            # 통계 저장
            if save_stats:
                try:
                    self.save_analysis_results(input_path, output_path)
                except Exception as e:
                    print(f"⚠️ 통계 저장 중 오류: {e}")
                    print("📊 기본 통계만 출력합니다:")
                    self.print_basic_stats()

            return self.frame_stats

        except Exception as e:
            print(f"❌ 처리 중 오류: {e}")
            return None
        finally:
            cap.release()
            if out:
                out.release()
