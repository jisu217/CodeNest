{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702c3906-82cd-4d24-9158-c030cc385cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install unstructured\n",
    "!pip install sentence-transformers\n",
    "!pip install chromadb\n",
    "!pip install openai\n",
    "!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8074baa0-6ee8-4e67-8e54-d1f1032fab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "from langchain.document_loaders import TextLoader\n",
    "documents = TextLoader(\"./datos/España.txt\").load()\n",
    "\n",
    "# 데이터의 문장을 청크로 분할. (큰 덩어리의 문서를 작은 덩어리로 분할)\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# (1) 문서를 청크로 분할\n",
    "def split_docs(documents, chunk_size = 1000, chunk_overlap = 20):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size,\n",
    "                                                   chunk_overlap=chunk_overlap)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    return docs\n",
    "\n",
    "# (2) docs 변수에 분할 문서를 저장\n",
    "docs = split_docs(documents)\n",
    "\n",
    "# 벡터 데이터베이스인 크로마에 임베딩 처리된 벡터를 저장. 임베딩 처리는 open ai 모델을 사용\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "api_key = \"write your api key\"\n",
    "embeddings = OpenAIEmbeddings(model = \"text-embedding-ada-002\", api_key = api_key)\n",
    "\n",
    "# (1) Chromdb에 벡터 저장\n",
    "from langchain.vectorstores import Chroma\n",
    "db = Chroma.from_documents(docs, embeddings, persist_directory = \"./data\")\n",
    "\n",
    "# 텍스트 파일에서 관련 내용을 찾아 LLM에 제공하면 LLM이 답변을 생성\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "model_name = \"gpt-4-turbo\"\n",
    "llm = ChatOpenAI(model_name=model_name, api_key = api_key)\n",
    "\n",
    "#Q&A 체인을 사용하여 쿼리에 대한 답변 얻기\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\", verbose = True)\n",
    "\n",
    "#쿼리를 작성하고 유사도 검색을 수행하여 답변을 생성, 따라서 텍스트에 있는 내용을 물어봐야 함\n",
    "query = \"¿Dónde está España?\"\n",
    "matching_docs = db.similarity_search(query)\n",
    "answer = chain.run(input_documents = matching_docs, question = query)\n",
    "answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
