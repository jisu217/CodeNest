# YOLO ì›¹ìº  ì‹¤ì‹œê°„ íƒì§€ ì—°ìŠµìš© - ë¡œì»¬ ë¹„ë””ì˜¤ íŒŒì¼ ì‚¬ìš©

import cv2
from ultralytics import YOLO
import time
import os


# =============================================
# 2. ìƒ˜í”Œ ë™ì˜ìƒ ìë™ ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜
# =============================================
def get_local_video_file():

    print("=== ë¡œì»¬ ë¹„ë””ì˜¤ íŒŒì¼ ì„ íƒ ===")
    print("ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    print("ì˜ˆì‹œ: C:/Videos/sample.mp4 ë˜ëŠ” ./my_video.mp4")
    print("ì§€ì› í˜•ì‹: .mp4, .avi, .mov, .mkv, .wmv")

    while True:
        video_path = input("\në¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ: ").strip()

        # ë”°ì˜´í‘œ ì œê±° (ë“œë˜ê·¸&ë“œë¡­ ì‹œ ìƒê¸°ëŠ” ë”°ì˜´í‘œ)
        video_path = video_path.strip('"').strip("'")

        if not video_path:
            print("ê²½ë¡œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
            continue

        if not os.path.exists(video_path):
            print(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
            print("ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            continue

        video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm']
        if not any(video_path.lower().endswith(ext) for ext in video_extensions):
            print("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.")
            print(f"ì§€ì› í˜•ì‹: {', '.join(video_extensions)}")
            continue

        test_cap = cv2.VideoCapture(video_path)
        if not test_cap.isOpened():
            print("ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì´ ì†ìƒë˜ì—ˆê±°ë‚˜ ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            test_cap.release()
            continue

        fps = test_cap.get(cv2.CAP_PROP_FPS)
        frame_count = int(test_cap.get(cv2.CAP_PROP_FRAME_COUNT))
        width = int(test_cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(test_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        duration = frame_count / fps if fps > 0 else 0

        print(f"\nâœ“ ë¹„ë””ì˜¤ íŒŒì¼ ì •ë³´:")
        print(f"  - í•´ìƒë„: {width}x{height}")
        print(f"  - FPS: {fps:.1f}")
        print(f"  - ì´ í”„ë ˆì„: {frame_count}")
        print(f"  - ê¸¸ì´: {duration:.1f}ì´ˆ")

        test_cap.release()
        return video_path


# =============================================
# 3. ê°œì„ ëœ ì‹¤ì‹œê°„ íƒì§€ ì½”ë“œ
# =============================================

class RealTimeYOLO:
    def __init__(self, model_name='yolov8n.pt', confidence_threshold=0.5):
        """
        ì‹¤ì‹œê°„ YOLO íƒì§€ í´ë˜ìŠ¤

        Args:
            model_name: ì‚¬ìš©í•  YOLO ëª¨ë¸ ('yolov8n.pt', 'yolov8s.pt', etc.)
            confidence_threshold: íƒì§€ ì‹ ë¢°ë„ ì„ê³„ê°’
        """
        self.model = YOLO(model_name)
        self.confidence_threshold = confidence_threshold
        self.fps_counter = 0
        self.start_time = time.time()

    def calculate_fps(self):
        """ì‹¤ì œ FPS ê³„ì‚°"""
        self.fps_counter += 1
        elapsed_time = time.time() - self.start_time

        if elapsed_time >= 1.0:  # 1ì´ˆë§ˆë‹¤ FPS ì—…ë°ì´íŠ¸
            fps = self.fps_counter / elapsed_time
            self.fps_counter = 0
            self.start_time = time.time()
            return fps
        return None

    def detect_webcam(self, camera_index=0):
        cap = cv2.VideoCapture(camera_index)

        # ì›¹ìº  ì„¤ì • ìµœì í™”
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        cap.set(cv2.CAP_PROP_FPS, 30)

        if not cap.isOpened():
            print("ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            return

        print("ì›¹ìº  ì‹¤ì‹œê°„ íƒì§€ ì‹œì‘ (ì¢…ë£Œ: 'q' í‚¤)")
        current_fps = 0

        while True:
            ret, frame = cap.read()
            if not ret:
                print("í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
                break

            # YOLO íƒì§€ ì‹¤í–‰
            results = self.model(frame, conf=self.confidence_threshold, verbose=False)

            # ê²°ê³¼ ì‹œê°í™”
            annotated_frame = results[0].plot()

            # FPS ê³„ì‚° ë° í‘œì‹œ
            fps = self.calculate_fps()
            if fps is not None:
                current_fps = fps

            cv2.putText(annotated_frame, f'FPS: {current_fps:.1f}',
                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

            # íƒì§€ëœ ê°ì²´ ìˆ˜ í‘œì‹œ
            num_detections = len(results[0].boxes) if results[0].boxes is not None else 0
            cv2.putText(annotated_frame, f'Objects: {num_detections}',
                        (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)

            # í™”ë©´ í‘œì‹œ
            cv2.imshow('YOLO Real-time Detection', annotated_frame)

            # ì¢…ë£Œ ì¡°ê±´
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

        cap.release()
        cv2.destroyAllWindows()

    def detect_video_file(self, video_path, save_output=False, output_path=None):
        cap = cv2.VideoCapture(video_path)

        if not cap.isOpened():
            print(f"ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
            return

        # ë¹„ë””ì˜¤ ì •ë³´
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        original_fps = cap.get(cv2.CAP_PROP_FPS)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

        print(f"ë¹„ë””ì˜¤ íŒŒì¼ íƒì§€ ì‹œì‘: {video_path}")
        print(f"ì´ í”„ë ˆì„: {total_frames}, ì›ë³¸ FPS: {original_fps:.1f}")
        print("ì¢…ë£Œ: 'q' í‚¤, ì¼ì‹œì •ì§€: ìŠ¤í˜ì´ìŠ¤ë°”")

        # ê²°ê³¼ ì˜ìƒ ì €ì¥ ì„¤ì •
        out = None
        if save_output:
            if output_path is None:
                base_name = os.path.splitext(os.path.basename(video_path))[0]
                output_path = f"yolo_result_{base_name}_{int(time.time())}.mp4"

            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(output_path, fourcc, original_fps, (width, height))
            print(f"ê²°ê³¼ ì˜ìƒ ì €ì¥ ê²½ë¡œ: {output_path}")

        frame_count = 0
        paused = False
        current_fps = 0

        while True:
            if not paused:
                ret, frame = cap.read()
                if not ret:
                    print("ë¹„ë””ì˜¤ ëì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤!")
                    break

                frame_count += 1

                # YOLO íƒì§€ ì‹¤í–‰
                results = self.model(frame, conf=self.confidence_threshold, verbose=False)

                # ê²°ê³¼ ì‹œê°í™”
                annotated_frame = results[0].plot()

                # ì •ë³´ í‘œì‹œ
                fps = self.calculate_fps()
                if fps is not None:
                    current_fps = fps

                # ìƒíƒœ ì •ë³´ ì˜¤ë²„ë ˆì´
                info_text = [
                    f'FPS: {current_fps:.1f}',
                    f'Frame: {frame_count}/{total_frames}',
                    f'Progress: {frame_count / total_frames * 100:.1f}%'
                ]

                for i, text in enumerate(info_text):
                    cv2.putText(annotated_frame, text, (10, 30 + i * 25),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

                # íƒì§€ëœ ê°ì²´ ì •ë³´
                if results[0].boxes is not None:
                    for j, box in enumerate(results[0].boxes):
                        class_name = self.model.names[int(box.cls[0])]
                        confidence = float(box.conf[0])
                        cv2.putText(annotated_frame, f'{class_name}: {confidence:.2f}',
                                    (10, 120 + j * 20), cv2.FONT_HERSHEY_SIMPLEX,
                                    0.5, (255, 255, 0), 1)

                # ê²°ê³¼ ì˜ìƒ ì €ì¥
                if save_output and out is not None:
                    out.write(annotated_frame)

            # í™”ë©´ í‘œì‹œ
            cv2.imshow('YOLO Video Detection', annotated_frame)

            # í‚¤ ì…ë ¥ ì²˜ë¦¬
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
            elif key == ord(' '):  # ìŠ¤í˜ì´ìŠ¤ë°”ë¡œ ì¼ì‹œì •ì§€/ì¬ìƒ
                paused = not paused
                print("ì¼ì‹œì •ì§€" if paused else "ì¬ìƒ")

        cap.release()
        if out is not None:
            out.release()
            print(f"âœ“ ê²°ê³¼ ì˜ìƒ ì €ì¥ ì™„ë£Œ: {output_path}")
        cv2.destroyAllWindows()

        return output_path if save_output else None


# =============================================
# 4. ë‹¤ì–‘í•œ íƒì§€ ëª¨ë“œ í•¨ìˆ˜
# =============================================

def detection_with_tracking():
    """ê°ì²´ íƒì§€ + ì¶”ì """
    model = YOLO('yolov8n.pt')
    cap = cv2.VideoCapture(0)

    track_history = {}

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        results = model.track(frame, persist=True, verbose=False)

        if results[0].boxes is not None and results[0].boxes.id is not None:
            boxes = results[0].boxes.xywh.cpu()
            track_ids = results[0].boxes.id.int().cpu().tolist()

            for box, track_id in zip(boxes, track_ids):
                x, y, w, h = box
                center = (int(x), int(y))

                if track_id not in track_history:
                    track_history[track_id] = []
                track_history[track_id].append(center)

                if len(track_history[track_id]) > 30:
                    track_history[track_id].pop(0)

        annotated_frame = results[0].plot()

        for track_id, points in track_history.items():
            if len(points) > 1:
                for i in range(1, len(points)):
                    cv2.line(annotated_frame, points[i - 1], points[i],
                             (0, 255, 255), 2)

        cv2.imshow('YOLO Detection + Tracking', annotated_frame)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()


def batch_process_videos(input_folder, output_folder=None):
    """í´ë” ë‚´ ëª¨ë“  ë¹„ë””ì˜¤ íŒŒì¼ì„ ì¼ê´„ ì²˜ë¦¬"""

    if output_folder is None:
        output_folder = os.path.join(input_folder, "yolo_results")

    os.makedirs(output_folder, exist_ok=True)

    # ì§€ì›í•˜ëŠ” ë¹„ë””ì˜¤ í˜•ì‹
    video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm']

    # ë¹„ë””ì˜¤ íŒŒì¼ ì°¾ê¸°
    video_files = []
    for file in os.listdir(input_folder):
        if any(file.lower().endswith(ext) for ext in video_extensions):
            video_files.append(file)

    if not video_files:
        print(f"í´ë”ì—ì„œ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_folder}")
        return

    print(f"ì´ {len(video_files)}ê°œì˜ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.")

    # YOLO ëª¨ë¸ ì´ˆê¸°í™”
    model = YOLO('yolov8n.pt')

    for i, filename in enumerate(video_files, 1):
        input_path = os.path.join(input_folder, filename)
        base_name = os.path.splitext(filename)[0]
        output_path = os.path.join(output_folder, f"yolo_{base_name}.mp4")

        print(f"\n[{i}/{len(video_files)}] ì²˜ë¦¬ ì¤‘: {filename}")

        try:
            # ë¹„ë””ì˜¤ ì²˜ë¦¬
            cap = cv2.VideoCapture(input_path)
            fps = cap.get(cv2.CAP_PROP_FPS)
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

            # ì¶œë ¥ ë¹„ë””ì˜¤ ì„¤ì •
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

            frame_count = 0
            while True:
                ret, frame = cap.read()
                if not ret:
                    break

                # YOLO íƒì§€
                results = model(frame, verbose=False)
                annotated_frame = results[0].plot()

                # ì§„í–‰ë¥  í‘œì‹œ
                frame_count += 1
                if frame_count % 30 == 0:  # 30í”„ë ˆì„ë§ˆë‹¤ ì¶œë ¥
                    progress = (frame_count / total_frames) * 100
                    print(f"  ì§„í–‰ë¥ : {progress:.1f}% ({frame_count}/{total_frames})")

                out.write(annotated_frame)

            cap.release()
            out.release()
            print(f"âœ“ ì™„ë£Œ: {output_path}")

        except Exception as e:
            print(f"âœ— ì‹¤íŒ¨: {filename} - {e}")

    print(f"\nì¼ê´„ ì²˜ë¦¬ ì™„ë£Œ! ê²°ê³¼ í´ë”: {output_folder}")


def save_detection_report(video_path, output_dir=None):
    """íƒì§€ ê²°ê³¼ë¥¼ CSV ë¦¬í¬íŠ¸ë¡œ ì €ì¥"""

    if output_dir is None:
        output_dir = os.path.dirname(video_path)

    base_name = os.path.splitext(os.path.basename(video_path))[0]
    report_path = os.path.join(output_dir, f"detection_report_{base_name}.csv")

    model = YOLO('yolov8n.pt')
    cap = cv2.VideoCapture(video_path)

    # CSV íŒŒì¼ ìƒì„±
    import csv
    with open(report_path, 'w', newline='', encoding='utf-8') as csvfile:
        fieldnames = ['frame_number', 'timestamp', 'object_class', 'confidence', 'x1', 'y1', 'x2', 'y2']
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()

        frame_number = 0
        fps = cap.get(cv2.CAP_PROP_FPS)

        while True:
            ret, frame = cap.read()
            if not ret:
                break

            frame_number += 1
            timestamp = frame_number / fps

            # YOLO íƒì§€
            results = model(frame, verbose=False)

            if results[0].boxes is not None:
                for box in results[0].boxes:
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    confidence = float(box.conf[0])
                    class_name = model.names[int(box.cls[0])]

                    writer.writerow({
                        'frame_number': frame_number,
                        'timestamp': f"{timestamp:.2f}",
                        'object_class': class_name,
                        'confidence': f"{confidence:.3f}",
                        'x1': f"{x1:.1f}",
                        'y1': f"{y1:.1f}",
                        'x2': f"{x2:.1f}",
                        'y2': f"{y2:.1f}"
                    })

            if frame_number % 100 == 0:
                print(f"ë¦¬í¬íŠ¸ ìƒì„± ì¤‘... í”„ë ˆì„: {frame_number}")

    cap.release()
    print(f"âœ“ íƒì§€ ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: {report_path}")
    return report_path
    """íŠ¹ì • ê°ì²´ ê°œìˆ˜ ì„¸ê¸°"""
    model = YOLO('yolov8n.pt')
    cap = cv2.VideoCapture(0)

    # ê´€ì‹¬ ìˆëŠ” í´ë˜ìŠ¤ë“¤
    target_classes = ['person', 'car', 'bicycle', 'motorbike']

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        results = model(frame, verbose=False)
        annotated_frame = results[0].plot()

        # í´ë˜ìŠ¤ë³„ ê°œìˆ˜ ê³„ì‚°
        if results[0].boxes is not None:
            class_counts = {}
            for box in results[0].boxes:
                class_name = model.names[int(box.cls[0])]
                if class_name in target_classes:
                    class_counts[class_name] = class_counts.get(class_name, 0) + 1

            # ê°œìˆ˜ ì •ë³´ í‘œì‹œ
            y_offset = 30
            for class_name, count in class_counts.items():
                text = f'{class_name}: {count}'
                cv2.putText(annotated_frame, text, (10, y_offset),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
                y_offset += 30

        cv2.imshow('YOLO Object Counting', annotated_frame)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()


# =============================================
# 5. ì‚¬ìš© ì˜ˆì‹œ ë° ì‹¤í–‰ ì½”ë“œ
# =============================================

if __name__ == "__main__":
    # YOLO íƒì§€ê¸° ì´ˆê¸°í™”
    detector = RealTimeYOLO(model_name='yolov8n.pt', confidence_threshold=0.3)

    print("\n=== ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“œ ===")
    print("1. ì›¹ìº  ì‹¤ì‹œê°„ íƒì§€")
    print("2. ë¡œì»¬ ë¹„ë””ì˜¤ íŒŒì¼ íƒì§€ (í™”ë©´ ë³´ê¸°ë§Œ)")
    print("3. ë¡œì»¬ ë¹„ë””ì˜¤ íŒŒì¼ íƒì§€ + ê²°ê³¼ ì˜ìƒ ì €ì¥")
    print("4. í´ë” ë‚´ ëª¨ë“  ë¹„ë””ì˜¤ ì¼ê´„ ì²˜ë¦¬")
    print("5. íƒì§€ ê²°ê³¼ CSV ë¦¬í¬íŠ¸ ìƒì„±")
    print("6. ê°ì²´ ì¶”ì  ëª¨ë“œ (ì›¹ìº )")
    print("7. ê°ì²´ ê°œìˆ˜ ì„¸ê¸° ëª¨ë“œ (ì›¹ìº )")

    mode = input("\nëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš” (1-7): ")

    if mode == '1':
        # ì›¹ìº  ì‹¤ì‹œê°„ íƒì§€
        detector.detect_webcam()

    elif mode == '2':
        # ë¡œì»¬ ë¹„ë””ì˜¤ íŒŒì¼ íƒì§€ (ì €ì¥ ì•ˆí•¨)
        video_path = get_local_video_file()
        if video_path:
            print(f"\në¹„ë””ì˜¤ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤: {os.path.basename(video_path)}")
            print("ì¡°ì‘ë²•:")
            print("  - 'q': ì¢…ë£Œ")
            print("  - ìŠ¤í˜ì´ìŠ¤ë°”: ì¼ì‹œì •ì§€/ì¬ìƒ")
            input("ì—”í„°ë¥¼ ëˆŒëŸ¬ ì‹œì‘í•˜ì„¸ìš”...")
            detector.detect_video_file(video_path, save_output=False)

    elif mode == '3':
        # ë¡œì»¬ ë¹„ë””ì˜¤ íŒŒì¼ íƒì§€ + ê²°ê³¼ ì €ì¥
        video_path = get_local_video_file()
        if video_path:
            # ì €ì¥ ê²½ë¡œ ì„¤ì •
            base_name = os.path.splitext(os.path.basename(video_path))[0]
            default_output = f"yolo_result_{base_name}_{int(time.time())}.mp4"

            print(f"\nê¸°ë³¸ ì €ì¥ ê²½ë¡œ: {default_output}")
            custom_path = input("ë‹¤ë¥¸ ê²½ë¡œë¥¼ ì›í•˜ë©´ ì…ë ¥í•˜ì„¸ìš” (ì—”í„°: ê¸°ë³¸ê°’ ì‚¬ìš©): ").strip()
            output_path = custom_path if custom_path else default_output

            print(f"\në¹„ë””ì˜¤ ë¶„ì„ ë° ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤: {os.path.basename(video_path)}")
            print(f"ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {output_path}")
            print("ì¡°ì‘ë²•:")
            print("  - 'q': ì¢…ë£Œ")
            print("  - ìŠ¤í˜ì´ìŠ¤ë°”: ì¼ì‹œì •ì§€/ì¬ìƒ")
            input("ì—”í„°ë¥¼ ëˆŒëŸ¬ ì‹œì‘í•˜ì„¸ìš”...")

            saved_path = detector.detect_video_file(video_path, save_output=True, output_path=output_path)
            if saved_path:
                print(f"\nğŸ‰ ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì˜ìƒì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:")
                print(f"ğŸ“ {os.path.abspath(saved_path)}")

    elif mode == '4':
        # í´ë” ë‚´ ëª¨ë“  ë¹„ë””ì˜¤ ì¼ê´„ ì²˜ë¦¬
        folder_path = input("ë¹„ë””ì˜¤ íŒŒì¼ë“¤ì´ ìˆëŠ” í´ë” ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip().strip('"').strip("'")

        if os.path.exists(folder_path):
            output_folder = input("ê²°ê³¼ ì €ì¥ í´ë” (ì—”í„°: ìë™ ìƒì„±): ").strip()
            output_folder = output_folder if output_folder else None

            print(f"\ní´ë” ë‚´ ëª¨ë“  ë¹„ë””ì˜¤ íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤...")
            print("ì´ ì‘ì—…ì€ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            confirm = input("ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")

            if confirm.lower() == 'y':
                batch_process_videos(folder_path, output_folder)
        else:
            print("ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í´ë”ì…ë‹ˆë‹¤!")

    elif mode == '5':
        # íƒì§€ ê²°ê³¼ CSV ë¦¬í¬íŠ¸ ìƒì„±
        video_path = get_local_video_file()
        if video_path:
            print(f"\níƒì§€ ê²°ê³¼ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤: {os.path.basename(video_path)}")
            print("ì´ ì‘ì—…ì€ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤...")

            report_path = save_detection_report(video_path)
            print(f"\nğŸ“Š ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!")
            print(f"ğŸ“ {os.path.abspath(report_path)}")

    elif mode == '6':
        # ê°ì²´ ì¶”ì  ëª¨ë“œ
        print("ì›¹ìº ì„ ì‚¬ìš©í•œ ê°ì²´ ì¶”ì ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        detection_with_tracking()

    elif mode == '7':
        # ê°ì²´ ê°œìˆ˜ ì„¸ê¸° ëª¨ë“œ
        print("ì›¹ìº ì„ ì‚¬ìš©í•œ ê°ì²´ ê°œìˆ˜ ì„¸ê¸°ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        detection_with_counting()

    else:
        print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤!")
